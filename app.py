import streamlit as st
import chromadb
from openai import OpenAI
import os
from chromadb.utils import embedding_functions

# ==========================================
# 1. ê¸°ë³¸ ì„¤ì • ë° DB ì—°ê²°
# ==========================================
st.set_page_config(page_title="ì…ì‹œ ì»¨ì„¤íŒ… AI", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ ëŒ€ì… í•©ê²©ì˜ˆì¸¡ AI ì»¨ì„¤í„´íŠ¸")

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    api_key = st.sidebar.text_input("OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")

if not api_key:
    st.warning("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

@st.cache_resource
def get_collection(_api_key):
    try:
        openai_ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=_api_key,
            model_name="text-embedding-3-small"
        )
        client = chromadb.PersistentClient(path="./chroma_db")
        col = client.get_collection(name="admissions", embedding_function=openai_ef)
        return col
    except Exception as e:
        st.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

collection = get_collection(api_key)
if not collection: st.stop()

# ==========================================
# 2. (í•µì‹¬ ìˆ˜ì •) ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ë¡œì§
# ==========================================
@st.cache_data
def get_filter_options():
    """
    DBì—ì„œ í•™êµëª…ê³¼ ì „í˜•ì„ ê°€ì ¸ì™€ì„œ
    ë„ì–´ì“°ê¸°ê°€ ë‹¬ë¼ë„ ê°™ì€ ì˜ë¯¸ë©´ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.
    """
    try:
        data = collection.get(include=["metadatas"])
        
        # í•™êµëª… ì²˜ë¦¬
        school_set = set()
        
        # ì „í˜• ì²˜ë¦¬ (ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±)
        # ì˜ˆ: {'í•™ìƒë¶€êµê³¼ì „í˜•': ['í•™ìƒë¶€ êµê³¼ ì „í˜•', 'í•™ìƒë¶€ êµê³¼ì „í˜•']}
        type_map = {} 
        
        for meta in data['metadatas']:
            # í•™êµëª… ìˆ˜ì§‘
            if "í•™êµëª…" in meta and meta["í•™êµëª…"]:
                school_set.add(meta["í•™êµëª…"])
            
            # ì „í˜• ì´ë¦„ ì •ê·œí™” (ë„ì–´ì“°ê¸° ì œê±°)
            if "ì „í˜•" in meta and meta["ì „í˜•"]:
                raw_val = meta["ì „í˜•"]
                # ë„ì–´ì“°ê¸°ë¥¼ ëª¨ë‘ ì—†ì•¤ ì´ë¦„ì„ 'ëŒ€í‘œ ì´ë¦„'ìœ¼ë¡œ ì‚¬ìš©
                clean_name = raw_val.replace(" ", "")
                
                if clean_name not in type_map:
                    type_map[clean_name] = []
                # ì‹¤ì œ DBì— ìˆëŠ” ê°’ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ë‚˜ì¤‘ì— ê²€ìƒ‰í•  ë•Œ ì”€)
                if raw_val not in type_map[clean_name]:
                    type_map[clean_name].append(raw_val)

        return sorted(list(school_set)), type_map
    except:
        return [], {}

# í•™êµ ëª©ë¡ê³¼ ì „í˜• ë§¤í•‘ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
school_list, type_mapping = get_filter_options()

# ì‚¬ì´ë“œë°” í‘œì‹œìš© ì „í˜• ë¦¬ìŠ¤íŠ¸ (ë„ì–´ì“°ê¸° ì—†ëŠ” ê¹”ë”í•œ ì´ë¦„ë“¤)
display_types = ["ì „ì²´"] + sorted(list(type_mapping.keys()))

# ==========================================
# 3. ì‚¬ì´ë“œë°” UI
# ==========================================
st.sidebar.header("ğŸ“ í•™ìƒ ì •ë³´ ì…ë ¥")

target_school = st.sidebar.selectbox("í¬ë§ ëŒ€í•™", ["ì „ì²´"] + school_list)
# ì‚¬ìš©ìëŠ” ê¹”ë”í•œ ì´ë¦„("í•™ìƒë¶€êµê³¼ì „í˜•")ì„ ì„ íƒí•¨
selected_display_type = st.sidebar.selectbox("í¬ë§ ì „í˜•", display_types)

my_grade = st.sidebar.number_input(
    "ë‚´ì‹  ë“±ê¸‰ (ì§ì ‘ ì…ë ¥)", 
    min_value=1.00, max_value=9.00, value=3.00, step=0.00, format="%.2f"
)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“„ ìƒí™œê¸°ë¡ë¶€ ìˆ˜ì¤€")
record_level = st.sidebar.select_slider(
    "ìƒê¸°ë¶€ í€„ë¦¬í‹° ì„ íƒ",
    options=["í•˜ (ê¸°ë³¸)", "ì¤‘ (í‰ë²”)", "ìƒ (ìš°ìˆ˜)", "ìµœìƒ (íŠ¹ëª©ê³ )"],
    value="ì¤‘ (í‰ë²”)"
)

# ==========================================
# 4. RAG ë° ëŒ€í™” ë¡œì§
# ==========================================
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ëŒ€í•™/í•™ê³¼ë¥¼ ëª©í‘œë¡œ í•˜ì‹œë‚˜ìš”?"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            
            # --- 1. í•„í„° ì¡°ê±´ ìƒì„± (ê³ ê¸‰) ---
            where_conditions = []
            
            # í•™êµ í•„í„°
            if target_school != "ì „ì²´":
                where_conditions.append({"í•™êµëª…": target_school})
            
            # ì „í˜• í•„í„° (í•µì‹¬ ìˆ˜ì •!)
            if selected_display_type != "ì „ì²´":
                # ì‚¬ìš©ìê°€ ì„ íƒí•œ 'ê¹”ë”í•œ ì´ë¦„'ì— ì—°ê²°ëœ 'ì‹¤ì œ DB ê°’ë“¤'ì„ ëª¨ë‘ ê°€ì ¸ì˜´
                # ì˜ˆ: ["í•™ìƒë¶€ êµê³¼ ì „í˜•", "í•™ìƒë¶€ êµê³¼ì „í˜•"]
                real_db_values = type_mapping[selected_display_type]
                
                if len(real_db_values) == 1:
                    # ê°’ì´ í•˜ë‚˜ë©´ ë‹¨ìˆœ ì¼ì¹˜ ê²€ìƒ‰
                    where_conditions.append({"ì „í˜•": real_db_values[0]})
                else:
                    # ê°’ì´ ì—¬ëŸ¬ ê°œë©´ $in ì—°ì‚°ìë¡œ "ì´ê±° ì•„ë‹ˆë©´ ì €ê±°" ê²€ìƒ‰
                    where_conditions.append({"ì „í˜•": {"$in": real_db_values}})

            # ChromaDB where ì ˆ ì¡°í•©
            final_where = None
            if len(where_conditions) == 1:
                final_where = where_conditions[0]
            elif len(where_conditions) > 1:
                final_where = {"$and": where_conditions}

            # --- 2. ê²€ìƒ‰ ë° ë‹µë³€ ---
            try:
                results = collection.query(
                    query_texts=[prompt],
                    n_results=5,
                    where=final_where
                )
                
                docs = results['documents'][0]
                metas = results['metadatas'][0]
                
                context = ""
                if docs:
                    for i, doc in enumerate(docs):
                        # ì „í˜• ì´ë¦„ì„ ë³´ì—¬ì¤„ ë•Œë„ ê¹”ë”í•˜ê²Œ í‘œì‹œ ê°€ëŠ¥
                        context += f"[{metas[i]['í•™êµëª…']} {metas[i]['ì „í˜•']}] {doc}\n"
                else:
                    context = "ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì…ì‹œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."

                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìƒê¸°ë¶€ ë¡œì§ ë°˜ì˜)
                system_prompt = f"""
                ë‹¹ì‹ ì€ ì…ì‹œ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
                
                [í•™ìƒ ì •ë³´]
                - ë‚´ì‹ : {my_grade}ë“±ê¸‰
                - ìƒê¸°ë¶€: {record_level}
                
                [íŒë‹¨ ë¡œì§]
                1. ìƒê¸°ë¶€ 'ìƒ/ìµœìƒ': í•™ì¢… ì§€ì› ì‹œ ë‚´ì‹  ì»·ë³´ë‹¤ 0.5~0.8 ë‚®ì•„ë„ 'ì†Œì‹ /ì ì •' íŒì •.
                2. ìƒê¸°ë¶€ 'ì¤‘/í•˜': í•™ì¢…ë³´ë‹¤ëŠ” êµê³¼ ìœ„ì£¼ ì¶”ì²œ. ë‚´ì‹  ì»· ì¤€ìˆ˜ í•„ìˆ˜.
                3. ë°ì´í„°ì˜ '50% cut', '70% cut'ê³¼ í•™ìƒ ë‚´ì‹ ì„ ë¹„êµí•˜ì—¬ í•©ê²© í™•ë¥ (%)ì„ ì¶”ì •í•˜ì„¸ìš”.

                [ì…ì‹œ ë°ì´í„°]
                {context}
                
                ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
                """
                
                # ë©”ëª¨ë¦¬ ê¸°ëŠ¥
                msgs = [{"role": "system", "content": system_prompt}]
                msgs.extend(st.session_state.messages[-4:]) # ìµœê·¼ 4ê°œ ëŒ€í™” ê¸°ì–µ

                client = OpenAI(api_key=api_key)
                res = client.chat.completions.create(
                    model="gpt-4o",
                    messages=msgs,
                    temperature=0.2
                )
                answer = res.choices[0].message.content

            except Exception as e:
                answer = f"ì˜¤ë¥˜ ë°œìƒ: {e}"

            st.write(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})